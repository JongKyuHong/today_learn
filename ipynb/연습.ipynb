{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "연습.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKt3WaU3KhJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytorch를 활용한 자연어 처리 (NLP)\n",
        "# 출처 : https://zzsza.github.io/data/2018/03/10/nlp-python/\n",
        "# 사람은 문맥을 통해 각 단어의 유사함과 관계를 쉽게 추론할 수 있음 컴퓨터에게 넣기 위해선 컴퓨터가 이해할 수 있도록\n",
        "# 변형해줘야 합니다. 이 과정을 Word Representation이라고 합니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vode8ZicOt10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word Representation\n",
        "# Idea / Thing을 여러 Symbol로 표현할 수 있습니다. 여기서 각 단어간 관계도 알 수 있다.\n",
        "\n",
        "# WordNet\n",
        "# * 단어 의미를 그래프 형태로 출력\n",
        "# * 사람이 직접 구축해야 한다(비용이 비싸다)\n",
        "# * 신조어의 의미를 이해 못함\n",
        "# * 뉘앙스를 놓치기가 쉽다\n",
        "# * 주관적이다\n",
        "# * 단어 간의 정확한 유사도 계산이 어렵다(얼마나 유사한지) 그래프상 몇 노드가 연결되는지 정도만 알 수 있음\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGBx1kdvQ9cJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "92dfead2-20ed-4017-d2ef-dd1ac0f79016"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torchtext\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "tagger = Kkma()\n",
        "import gensim\n",
        "\n",
        "torchtext.vocab.pretrained_aliases\n",
        "\n",
        "corpus = open('data/corpus.txt','r',encoding=\"utf-8\").readlines()\n",
        "corpus = [c[:-1] for c in corpus]\n",
        "\n",
        "tokenized = [tagger.morphs(c) for c in corpus]\n",
        "\n",
        "model = gensim.models.Word2Vec(tokenized, size=15, window=5, min_count=2, workers=4)\n",
        "\n",
        "model.most_similar(\"토치\")\n",
        "\n",
        "model.wv.save_word2vec_format(\"data/word_vector_sample.bin\",binary=True) # 저장\n",
        "\n",
        "pretrained_vectors_model = gensim.models.KeyedVectors.load_word2vec_format(\"data/word_vector_sample.bin\",binary=True)\n",
        "\n",
        "pretrained_vectors_model['토치']\n",
        "\n",
        "vocab = list(pretrained_vectors_model.vocab.keys()) # Word2Vec에서 사용한 vocab\n",
        "\n",
        "pretrained_vectors=[]\n",
        "for vo in vocab:\n",
        "    pretrained_vectors.append(pretrained_vectors_model[vo])\n",
        "    \n",
        "pretrained_vectors = np.vstack(pretrained_vectors)\n",
        "\n",
        "pretrained_vectors.shape\n",
        "\n",
        "# Init embedding matrix\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self,vocab_size,embed_size):\n",
        "        super(MyModel,self).__init__()\n",
        "        \n",
        "        self.embed = nn.Embedding(vocab_size,embed_size)\n",
        "        \n",
        "    def init_embed(self,pretrained_vectors):\n",
        "        self.embed.weight.data = torch.from_numpy(pretrained_vectors).float()\n",
        "    \n",
        "    def forward(self,inputs):\n",
        "        return self.embed(inputs)\n",
        "\n",
        "model = MyModel(len(vocab),15)\n",
        "model.embed.weight\n",
        "model.init_embed(pretrained_vectors)\n",
        "model.embed.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4285d91c111e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKkma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPRw5J3aROSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}